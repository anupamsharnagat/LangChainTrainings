{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0617eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Installation of required dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb49e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.2 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain) (1.1.3)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.4.59)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.12.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
      "Requirement already satisfied: certifi in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\rnd\\langchain\\langchaintrainings\\langchaintrainings\\lenv312\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1742e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d0c154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f98880",
   "metadata": {},
   "source": [
    "####Intracting with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb89e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Okay, let\\'s break down **LangChain**.\\n\\n**In simple terms:**\\n\\nThink of LangChain as a **framework and a set of tools** specifically designed to help you **build applications and systems that use large language models (LLMs)** effectively.\\n\\n**Here\\'s a more detailed explanation:**\\n\\n1.  **The Core Problem:** Large language models (like GPT-4, Claude, Gemini, Llama, etc.) are incredibly powerful at generating human-like text. However, they often don\\'t have:\\n    *   **Context:** They don\\'t inherently understand the specific information you want them to use.\\n    *   **Structure:** They don\\'t naturally chain together multiple tasks or reasoning steps.\\n    *   **Integration:** They don\\'t easily connect to other tools, APIs, databases, or the real world.\\n\\n2.  **What LangChain Does:** LangChain provides the building blocks to overcome these limitations. It helps you:\\n    *   **Structure Interactions:** It provides tools like \"Chains\" to sequence LLM calls, combine their outputs, and manage complex reasoning tasks step-by-step.\\n    *   **Provide Context:** It offers ways to inject relevant information (like data from a database, documents, or previous conversation history) into the LLM\\'s input.\\n    *   **Integrate Tools:** It makes it easier to connect LLMs with external tools, APIs, search engines, databases, calculators, and more. The LLM can \"use\" these tools as part of its reasoning process.\\n    *   **Manage State & Memory:** It includes components to handle memory, keeping track of past interactions or relevant data for ongoing conversations or tasks.\\n\\n3.  **Key Concepts (The Building Blocks):**\\n\\n    *   **Language Models (LLMs):** The core AI engine (like GPT models). LangChain interacts with these.\\n    *   **Prompts:** Templates for how to ask the LLM questions or tasks. LangChain helps structure these.\\n    *   **Chains:** Sequences of operations (like LLM calls, tool calls, function calls, math calculations) connected together. This allows for complex workflows.\\n    *   **Agents:** More advanced chains that can take actions (like searching the web, calling tools) based on their goals, often using LLMs to decide what to do.\\n    *   **Memory:** Ways to store and retrieve relevant information during a conversation or task.\\n    *   **Tools:** Interfaces to connect the LLM to external functionalities (APIs, databases, search, calculators, etc.).\\n    *   **Indexes & Retrievers:** Ways to organize and search through large bodies of text (like documents, PDFs) to find relevant information for the LLM.\\n\\n4.  **Analogy:**\\n\\n    Imagine you have a super intelligent but clumsy assistant (the LLM). It\\'s brilliant at writing, summarizing, and answering questions, but it doesn\\'t know where things are, how to perform tasks, or how to use reference materials effectively.\\n\\n    LangChain provides the:\\n    *   **Address Book (Prompts & Memory):** So the assistant knows who it\\'s talking to and what the context is.\\n    *   **Delivery System (Chains & Agents):** So the assistant can break down complex requests into steps.\\n    *   **Map & Compass (Retrievers & Indexes):** So the assistant can find relevant information in books (documents) or on the internet (search).\\n    *   **Kitchen Utensils (Tools):** So the assistant can perform specific actions (calculating, looking things up externally).\\n\\n5.  **Use Cases:**\\n\\n    *   **AI Assistants:** Chatbots, virtual assistants that can answer questions, summarize emails, or help with tasks.\\n    *   **Content Generation:** Automatically writing summaries, stories, marketing copy, code snippets.\\n    *   **Research Tools:** Analyzing large documents, comparing data, finding answers in knowledge bases.\\n    *   **Data Analysis:** Generating reports from datasets.\\n    *   **Custom Applications:** Embedding LLM capabilities into existing software (e.g., a CRM system that can answer customer queries).\\n\\n**In essence, LangChain is the software infrastructure designed to make it easier and more structured to build applications that leverage the capabilities of large language models.** It acts as a bridge between the powerful but somewhat unstructured LLM and the structured needs of real-world applications.' additional_kwargs={} response_metadata={'model': 'deepseek-r1:8b', 'created_at': '2025-12-12T15:56:02.553764Z', 'done': True, 'done_reason': 'stop', 'total_duration': 16972364400, 'load_duration': 73118400, 'prompt_eval_count': 7, 'prompt_eval_duration': 7193479200, 'eval_count': 1376, 'eval_duration': 9535992200, 'logprobs': None, 'model_name': 'deepseek-r1:8b', 'model_provider': 'ollama'} id='lc_run--019b1346-7641-71b3-83e9-df51d404a3fe-0' usage_metadata={'input_tokens': 7, 'output_tokens': 1376, 'total_tokens': 1383}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"deepseek-r1:8b\", \n",
    "    temperature=0.5,\n",
    "    max_tokens=512\n",
    "    )\n",
    "response = llm.invoke(\"What is LangChain?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1d5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1546a62",
   "metadata": {},
   "source": [
    "####Load env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065672da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os   \n",
    "load_dotenv('./.env')\n",
    "print(\"Langsmith Tracing:\", os.getenv(\"LANGSMITH_PROJECT\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
